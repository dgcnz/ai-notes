---
authors:
  - "[[Alexander Kirillov|Alexander Kirillov]]"
  - "[[Eric Mintun|Eric Mintun]]"
  - "[[Nikhila Ravi|Nikhila Ravi]]"
  - "[[Hanzi Mao|Hanzi Mao]]"
  - "[[Chloe Rolland|Chloe Rolland]]"
  - "[[Laura Gustafson|Laura Gustafson]]"
  - "[[Tete Xiao|Tete Xiao]]"
  - "[[Spencer Whitehead|Spencer Whitehead]]"
  - "[[Alexander C. Berg|Alexander C. Berg]]"
  - "[[Wan-Yen Lo|Wan-Yen Lo]]"
  - "[[Piotr Dollár|Piotr Dollár]]"
  - "[[Ross Girshick|Ross Girshick]]"
year: 2023
tags:
  - paper
  - segmentation
  - computer_vision
  - foundation_models
url: https://arxiv.org/abs/2304.02643
share: true
---
> [!tldr] Abstract
> We introduce the Segment Anything (SA) project: a new task, model, and dataset for image segmentation. Using our efficient model in a data collection loop, we built the largest segmentation dataset to date (by far), with over 1 billion masks on 11M licensed and privacy respecting images. The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks. We evaluate its capabilities on numerous tasks and find that its zero-shot performance is impressive -- often competitive with or even superior to prior fully supervised results. We are releasing the Segment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and 11M images at [this https URL](https://segment-anything.com/) to foster research into foundation models for computer vision.


